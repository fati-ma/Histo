# -*- coding: utf-8 -*-
""" Histopathology Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15KRCkgkUy2BjUU-U0rLPUwYxRHqcSVTb
"""

#Some of the segments in this code are highly dependant on extenral resources in order to establish a rough structure. These will be ammended through the following weeks.
from skimage import io, color, exposure, transform
from skimage import filters, util
import matplotlib.pyplot as plt
from google.colab import drive
from numpy import asarray
import skimage.io as io
from PIL import Image
from tqdm import tqdm
from glob import glob
import random as rnd
import random as rnd
import pandas as pd
import numpy as np
import torch
import os

"""The following code is for partial data augmentation. The final procedures regarding the complete implementation are not yet fully honed."""

from glob import glob

patches = glob("/content/drive/MyDrive/Colab Notebooks/IDC_regular_ps50_idx5/**/*.png", recursive=True)

print(len(patches))
print(type(patches))

labels = []
for i in range(len(patches)):
  labels.append(0) if("class0.png" in patches[i]) else labels.append(1)

data = {'Image_Name':patches, 'labels':labels}

dataframe = pd.DataFrame(data)

print(dataframe.describe())
print()
print(dataframe.info())

for i in range(5):
  print(patches[i])

#@title Show
from tqdm import tqdm

neg = []
pos = []
for i in tqdm(range(20000):
#  rand = rnd.randint(0, len(patches))
  name = patches[i]
  x = patches[i]
  x = io.imread(x)
  x = x/255.0
  neg.append(x) if("class0.png" in name) else pos.append(x)

print("Frequency of Negative class:",len(neg))
print("Frequency of Positive class:",len(pos))
#print(round((len(neg) / len(patches) * 100), 2))
#print(round((len(pos) / len(patches) * 100), 2))

dataframe.tail()

dataframe.sample()

pos = [] #Positive class
neg = [] #Negative class

for i in range(len(patches)):
    name = patches[i]
    #img = io.imread(name, as_gray=False)
    #img = np.array(img, dtype='float')
    # normalizing 
    #img /= 255.0
    #img = img.astype('float32')
    neg.append(patches[i]) if("class0.png" in name) else pos.append(patches[i])

classes = ["0", "1"]
freq = [len(neg), len(pos)]
plt.bar(classes, freq)
plt.show()

from sklearn.model_selection import train_test_split

train, val = train_test_split(dataframe, stratify=dataframe.labels, test_size=0.2)
len(train), len(val)

from torch.utils.data import TensorDataset, DataLoader, Dataset

class MyDataset(Dataset):
    def __init__(self, df_data,transform=None):
        super().__init__()
        self.df = df_data.values
        
        self.transform = transform

    def __len__(self):
        return len(self.df)
    
    def __getitem__(self, index):
        img_path,label = self.df[index]
        
        image = cv2.imread(img_path)
        image = cv2.resize(image, (50,50))
        if self.transform is not None:
            image = self.transform(image)
        return image, label

#Just to check
import torchvision.transforms as transforms

trans_train = transforms.Compose([transforms.ToPILImage(),
                                  transforms.Pad(64, padding_mode='reflect'),
                                  transforms.RandomHorizontalFlip(), 
                                  transforms.RandomVerticalFlip(),
                                  transforms.RandomRotation(20), 
                                  transforms.ToTensor(),
                                  transforms.Normalize(mean=[0.5, 0.5, 0.5],std=[0.5, 0.5, 0.5])])

trans_valid = transforms.Compose([transforms.ToPILImage(),
                                  transforms.Pad(64, padding_mode='reflect'),
                                  transforms.ToTensor(),
                                  transforms.Normalize(mean=[0.5, 0.5, 0.5],std=[0.5, 0.5, 0.5])])

dataset_train = MyDataset(df_data=train, transform=trans_train)
dataset_valid = MyDataset(df_data=val,transform=trans_valid)

loader_train = DataLoader(dataset = dataset_train, batch_size=128, shuffle=True, num_workers=0)
loader_valid = DataLoader(dataset = dataset_valid, batch_size=128//2, shuffle=False, num_workers=0)

print(dataset_train)

#Sequential Module
from torch import nn

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        
        self.features = nn.Sequential(nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=2), 
                                      nn.BatchNorm2d(32), nn.ReLU(inplace=True), nn.MaxPool2d(2, 2),
                                      nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=2), 
                                      nn.BatchNorm2d(64), nn.ReLU(inplace=True), nn.MaxPool2d(2, 2),
                                      nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=2),
                                      nn.BatchNorm2d(128), nn.ReLU(inplace=True), nn.MaxPool2d(2, 2),
                                      nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=2),
                                      nn.BatchNorm2d(256), nn.ReLU(inplace=True), nn.MaxPool2d(2, 2),
                                      nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=2),
                                      nn.BatchNorm2d(512), nn.ReLU(inplace=True), nn.AvgPool2d(8),)
        self.classifier = nn.Sequential(nn.Linear(512 * 1 * 1, 2))
        
    def forward(self, x):
        x = self.features(x)
        x = x.view(x.size(0), -1)
        x = self.classifier(x)
        return x

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
model = Net().to(device)

from torch import optim

model = Net()
optimizer = optim.Adam(model.parameters(), lr=2e-3)
crit = nn.CrossEntropyLoss()
print(model)

total_step = len(loader_train)

losses = []
for epoch in range(10):
    for i, (images, labels) in enumerate(loader_train):
        images = images.to(device)
        labels = labels.to(device)
        outputs = model(images)
        loss = crit(outputs, labels)
        losses.append(loss)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        if (i+1) % 2 == 0:
            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' 
                   .format(epoch+1, 10, i+1, total_step, loss.item()))

plt.plot(losses, label="Trainning Losses")
plt.legend()
plt.show()

def augment(im):
  choose = rnd.randint(0, 4)
  if(choose == 0): 
    x = [45, 90, 180, -45, -90]
    x = x[rnd.randint(0, 4)]
    rot = transform.rotate(im, angle=x, mode="wrap")
    return rot
  if(choose == 1):
    flip_u = np.flipud(im)
    return flip_u
  if(choose == 2):
    flip_r = np.fliplr(im)
    return flip_r
  if(choose == 3):
    blur = filters.gaussian(im, sigma=0.6, multichannel=True)
    return blur
  if(choose == 4):
    noise = util.random_noise(im, var=0.155**2)
    return noise

def show_image(image, title='Image', cmap_type='gray'):    
    plt.imshow(image, cmap=cmap_type)        
    plt.title(title)    
    plt.axis('off')    
    plt.show()

